# -*- coding: utf-8 -*-
"""Bank loan default prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JiEJj663pD3HzjFIyCvUn07VUXAjZXNF

# **Loan default prediction**

## **Context**

A major proportion of retail bank profit comes from interests in the form of home loans. These loans are borrowed by regular income/high-earning customers. Banks are most fearful of defaulters, as bad loans (NPA) usually eat up a major chunk of their profits. Therefore, it is important for banks to be judicious while approving loans for their customer base.

The approval process for the loans is multifaceted. Through this process, the bank tries to check the creditworthiness of the applicant on the basis of a manual study of various aspects of the application. The entire process is not only effort-intensive but also prone to wrong judgment/approval owing to human error and biases.

There have been attempts by many banks to automate this process by using heuristics. But with the advent of data science and machine learning, the focus has shifted to building machines that can learn this approval process and make it free of biases and more efficient. At the same time, one important thing to keep in mind is to make sure that the machine does not learn the biases that previously crept in because of the human approval process.

## **Problem Statement**

A bank's consumer credit department aims to simplify the decision-making process for home equity lines of credit to be accepted. To do this, they will adopt the Equal Credit Opportunity Act's guidelines to establish an empirically derived and statistically sound model for credit scoring. The model will be based on the data obtained via the existing loan underwriting process from recent applicants who have been given credit. The model will be built from predictive modeling techniques,
but the model created must be interpretable enough to provide a justification for any adverse behavior (rejections).

## **Objective**

Build a classification model to predict clients who are likely to default on their loan and give recommendations to the bank on the important features to consider while approving a loan.

## **Importing the required libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_theme()

# To scale the data using z-score
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split

# Algorithms to use
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis

from sklearn.linear_model import LogisticRegression

# Metrics to evaluate the model
from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, recall_score, f1_score

from sklearn import metrics

from sklearn import tree

from sklearn.tree import DecisionTreeClassifier

from sklearn.ensemble import BaggingClassifier

from sklearn.ensemble import RandomForestClassifier

import scipy.stats as stats

# For tuning the model
from sklearn.model_selection import GridSearchCV

# To ignore warnings
import warnings
warnings.filterwarnings("ignore")

"""### **Loading the dataset**

"""

hm=pd.read_csv("hmeq.csv")

# Copying data to another variable to avoid any changes to original data
data=hm.copy()

# Displaying first five rows
data.head()

# Displaying last 5 rows
data.tail()

# Checking the shape of the data
data.shape

"""**Insights**

- There are 5960 rows each one them with 13 columns
- There are rows with missing values (Nan).
"""

# Checking info of the data
data.info()

"""**Insights**

- 11 of 13 columns have missing values.
- Only 2 columns are object: Reason and Job.
"""

# Analyzing missing values
(data.isnull().sum())

# Checking the percentage of missing values in the each column.
(data.isnull().sum()/data.shape[0] * 100)

"""**Insights**

- 5 columns (Value, Reason, Job, Clage, CLNO) have around 5% of missing values.
- 4 columns (Mortdue, Yog, Delinq, Ninq) have around 10% of missing values.
- 1 column (Debtinc) has more than 20% of missing values.
- In total, 10 of 13 columns have missing values.

### **Convert the data types**
"""

cols = data.select_dtypes(['object']).columns.tolist()
#adding target variable to this list as this is a classification problem and the target variable is categorical

cols.append('BAD')

cols

# Changing the data type of object type column to category.

for i in cols:
    data[i] = data[i].astype("category")

# Checking the info again and the datatype of different variable

data.info()

"""### **Analyze Summary Statistics of the dataset**"""

# Analyzing the summary statistics for numerical variables

num_cols = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']
data[num_cols].describe().T

"""**Insights**

- All numerical variables have big outliers (max values) compared to their mean.
- The big outliers of the variables LOAN, MORTDUE and VALUE means there are a few persons who receive very big loans compared to the majority.
- The outlier of DELINQ means there are few peoples who frequently doesn't make their payments.
- The DEBTINC has weird values. A mean of ~34 is larger than 1 meaning the average customer owe almost 34 time his own total incomes, which isn't very logic. This variable is supposed to be a ratio.
"""

# Checking summary for categorical data

data.describe(include=['category']).T

"""**Insights**

- BAD has only 2 values: the value 0 which means the client hasn't defaulted and has a frequency of 80%. This means the other 20% of clients have defaulted at least once.
- Around 69% (~2/3) of clients ask for loans to pay other liabilities and consumer debts.
- "Other" represents 42% of the client's jobs.

**Let's look at the unique values in all the categorical variables**
"""

# Checking the count of unique values in each categorical column

cols_cat= data.select_dtypes(['category'])

for i in cols_cat.columns:
    print('Unique values in',i, 'are :')
    print(data[i].value_counts(normalize = True))
    print('*'*40)

"""**Insights**

- 80% of client are non defaulted. 20% of them are defaulted.
- Around 69% ask for loans to pay other liabilities and consumer debts. ~30% ask for loans to make home improvements.
- There are six types of jobs: ~58% of those jobs are proffesional executives, Office employees, Managers, self employed, sales. The 42% is in Other job.

## **Exploratory Data Analysis (EDA) and Visualization**

### **1. Univariate Analysis - Numerical Data**
"""

# While doing uni-variate analysis of numerical variables we want to study their central tendency and dispersion.
# Let's write a function that will help us create boxplot and histogram for any input numerical variable.
# This function takes the numerical column as the input and return the boxplots and histograms for the variable.
# Let's see if this help us write faster and cleaner code.
def histogram_boxplot(feature, figsize=(15,10), bins = None):
    """ Boxplot and histogram combined
    feature: 1-d feature array
    figsize: size of fig (default (9,8))
    bins: number of bins (default None / auto)
    """
    f2, (ax_box2, ax_hist2) = plt.subplots(nrows = 2, # Number of rows of the subplot grid= 2
                                           sharex = True, # x-axis will be shared among all subplots
                                           gridspec_kw = {"height_ratios": (.25, .75)},
                                           figsize = figsize
                                           ) # creating the 2 subplots
    sns.boxplot(feature, ax=ax_box2, showmeans=True, color='violet') # boxplot will be created and a star will indicate the mean value of the column
    sns.distplot(feature, kde=F, ax=ax_hist2, bins=bins,palette="winter") if bins else sns.distplot(feature, kde=False, ax=ax_hist2) # For histogram
    ax_hist2.axvline(np.mean(feature), color='green', linestyle='--') # Add mean to the histogram
    ax_hist2.axvline(np.median(feature), color='black', linestyle='-') # Add median to the histogram

# Building the histogram boxplot for Loan
for i in num_cols:
    histogram_boxplot(data[i])

"""**Insights**

- The variable LOAN has a skewed distribution to the right with lot of big outliers compared to the mean.
- The variable MORTDUE has a skewed distribution to the right with lot of big outliers compared to the mean.
- The variable VALUE is slightly skewed to the right with many oultiers.
- The variable YOG is very skewed to the right and has a few outliers.
- The variable DEROG and DELINQ are discrete and are skewed to the right with some outliers.
- The variable CLAGE seems to follow a distribution normally shaped with two modes.
- The variable NINQ is skewed to the right with some outliers.
- The variable CLNO follows a normal shape distribution slightly skewed to the right.
- The variable DEBTINC follows a normal shape distribution with outliers at both sides.

### **2. Univariate Analysis - Categorical Data**
"""

# Function to create barplots that indicate percentage for each category.

def perc_on_bar(plot, feature):
    '''
    plot
    feature: categorical feature
    the function won't work if a column is passed in hue parameter
    '''

    total = len(feature) # length of the column
    for p in ax.patches:
        percentage = '{:.1f}%'.format(100 * p.get_height()/total) # percentage of each class of the category
        x = p.get_x() + p.get_width() / 2 - 0.05 # width of the plot
        y = p.get_y() + p.get_height()           # height of the plot
        ax.annotate(percentage, (x, y), size = 12) # annotate the percentage

    plt.show() # show the plot

"""#### Analyze Barplot for DELINQ"""

#Building barplot for DELINQ

for i in cols:
    plt.figure(figsize=(15,5))
    ax = sns.countplot(data[i],palette='winter')
    perc_on_bar(ax,data[i])

"""**Insights**

- DELINQ isn't a categorical variable.
- The variable JOB seems to follow a normal distribution.
- The other two variables REASON and BAD are just 80-20 and 70-30 respectively.

## **Bivariate Analysis**

### **Bivariate Analysis: Continuous and Categorical Variables**

#### Analyze BAD vs Loan
"""

plt.figure(figsize=(15,5))
sns.boxplot(data["BAD"],data['LOAN'],palette="PuBu")
plt.figure(figsize=(15,5))
sns.boxplot(data["BAD"],data['MORTDUE'],palette="PuBu")
plt.figure(figsize=(15,5))
sns.boxplot(data["BAD"],data['VALUE'],palette="PuBu")
plt.figure(figsize=(15,5))
sns.boxplot(data["BAD"],data['DEBTINC'],palette="PuBu")

"""**Insights**

- BAD vs LOAN: it seems that independently of the type of client (defaulted or not) they receive the same amount of loans.
- BAD vs MORTDUE: it seems that independently of the type of client (defaulted or not) they have the same amount due on the existing mortgage.
- BAD vs VALUE: it seems that independently of the type of client (defaulted or not) there is no difference in the current value of the property.
- BAD vs DEBTINC: both type of clients seems to have very similar ratio.

### **Bivariate Analysis: Two Continuous Variables**
"""

plt.figure(figsize=(7,5))
sns.scatterplot(data["LOAN"],data['MORTDUE'],palette="PuBu")
plt.figure(figsize=(7,5))
sns.scatterplot(data["LOAN"],data['DEBTINC'],palette="PuBu")
plt.figure(figsize=(7,5))
sns.scatterplot(data["LOAN"],data['VALUE'],palette="PuBu")
plt.figure(figsize=(7,5))
sns.scatterplot(data["VALUE"],data['MORTDUE'],palette="PuBu")
plt.figure(figsize=(7,5))
sns.scatterplot(data["VALUE"],data['DEBTINC'],palette="PuBu")

"""**Insights:**

- There is a linear correlation between the variables VALUE and MORTDUE.
- There is no linear correlation between any other pair of variables.

### **Bivariate Analysis:  BAD vs Categorical Variables**

**The stacked bar chart**
"""

### Function to plot stacked bar charts for categorical columns

def stacked_plot(x):
    sns.set(palette='nipy_spectral')
    tab1 = pd.crosstab(x,data['BAD'],margins=True)
    print(tab1)
    print('-'*120)
    tab = pd.crosstab(x,data['BAD'],normalize='index')
    tab.plot(kind='bar',stacked=True,figsize=(10,5))
    plt.legend(loc='lower left', frameon=False)
    plt.legend(loc="upper left", bbox_to_anchor=(1,1))
    plt.show()

"""#### Plot stacked bar plot for for LOAN and REASON"""

# Plotting stacked bar plot for BAD and REASON
stacked_plot(data['REASON'])
stacked_plot(data['JOB'])

"""**Insights**

- In the first chart we can see that independently of the loan's reason 80% are non defaulted and 20% are defaulted clients.
- In the second chart we can see that people in sales has the highest percentage of defaulted loans.
- Office employees and professional executive are the two kind of jobs with the lowest rate of defaulted loans.

### **Multivariate Analysis**

#### Analyze Correlation Heatmap for Numerical Variables
"""

# Separating numerical variables
numerical_col = data.select_dtypes(include=np.number).columns.tolist()

# Building correlation matrix for numerical columns
corr = data[numerical_col].corr()

# plotting the heatmap
plt.figure(figsize=(12,8))
sns.heatmap(corr,cmap='coolwarm',vmax=1,vmin=-1,
        fmt=".2f",
        annot = True,
        xticklabels=corr.columns,
        yticklabels=corr.columns);

# Building pairplot for the data with hue = 'BAD'

sns.pairplot(data, hue="BAD")

"""#### Treating Outliers"""

def treat_outliers(df,col):
    '''
    treats outliers in a varaible
    col: str, name of the numerical varaible
    df: data frame
    col: name of the column
    '''

    Q1=df[col].quantile(q = .25) # 25th quantile
    Q3=df[col].quantile(q = .75)  # 75th quantile
    IQR = Q3-Q1   # IQR Range
    Lower_Whisker = Q1 - 1.5*IQR  #define lower whisker
    Upper_Whisker = Q3 + 1.5*IQR  # define upper Whisker
    df[col] = np.clip(df[col], Lower_Whisker, Upper_Whisker) # all the values samller than Lower_Whisker will be assigned value of Lower_whisker
                                                            # and all the values above upper_whishker will be assigned value of upper_Whisker
    return df

def treat_outliers_all(df, col_list):
    '''
    treat outlier in all numerical varaibles
    col_list: list of numerical varaibles
    df: data frame
    '''
    for c in col_list:
        df = treat_outliers(df,c)

    return df

df_raw = data.copy()

numerical_col = df_raw.select_dtypes(include=np.number).columns.tolist()# getting list of numerical columns

df = treat_outliers_all(df_raw,numerical_col)

df

"""#### Adding new columns in the dataset for each column which has missing values"""

#For each column we create a binary flag for the row, if there is missing value in the row, then 1 else 0.
def add_binary_flag(df,col):
    '''
    df: It is the dataframe
    col: it is column which has missing values
    It returns a dataframe which has binary falg for missing values in column col
    '''
    new_col = str(col)
    new_col += '_missing_values_flag'
    df[new_col] = df[col].isna()
    return df

# list of columns that has missing values in it
missing_col = [col for col in df.columns if df[col].isnull().any()]

for colmn in missing_col:
    add_binary_flag(df,colmn)

"""#### Filling missing values in numerical columns with median and mode in categorical variables"""

#  Treating Missing values in numerical columns with median and mode in categorical variables
# Select numeric columns.
num_data = df.select_dtypes('number')

# Selecting string and object columns.
cat_data = df.select_dtypes('category').columns.tolist() #df.select_dtypes('object')

# Filling numeric columns with median.
df.fillna(value = df.median(), inplace = True)

# Filling object columns with model.
for column in cat_data:
    mode = df[column].mode()[0]
    df[column].fillna(df[column].mode()[0], inplace=True)

df.isnull().sum()

df.head()

df.tail()

df.info()

"""### **Droping missing value flags**"""

#creating a list of bool features
bool_cols = df.select_dtypes(['bool']).columns.tolist()

#droping missing value flags
X = df.drop(columns = bool_cols)

X.info()

"""## **Data Preparation**

### **Separating the target variable from other variables**
"""

# Separating the target variable and other variables
Y = X.BAD
X = X.drop(columns = ['BAD'])

# Creating dummy variables for the categorical variables

# Creating the list of columns for which we need to create the dummy variables
to_get_dummies_for = ['REASON', 'JOB']

# Creating dummy variables
X = pd.get_dummies(data = X, columns = to_get_dummies_for, drop_first = True)

"""### **Scaling the data**

In this case features have different scales, so we will use the Standard Scaler method, which centers and scales the dataset using the Z-Score.
"""

# Scaling the data
sc = StandardScaler()

X_scaled = sc.fit_transform(X)

X_scaled = pd.DataFrame(X_scaled, columns = X.columns)

"""### **Splitting the data into 70% train and 30% test set**

The data is unbalanced (~80% is non defaulted and ~20% is defaulted). For this reason, we will use **stratified sampling** technique to ensure that relative class frequencies are approximately preserved in each train and validation fold.
"""

# Splitting the data into training and test set

x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size = 0.3, random_state = 1, stratify = Y)

"""## **Model Evaluation Criterion**

"""

#creating metric function
def metrics_score(actual, predicted):
    print(classification_report(actual, predicted))
    cm = confusion_matrix(actual, predicted)
    plt.figure(figsize=(8,5))
    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels=['Not Eligible', 'Eligible'], yticklabels=['Not Eligible', 'Eligible'])
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()

"""### **Building a Logistic Regression Model**

- Logistic Regression is a supervised learning algorithm, generally used for **binary classification problems**, i.e., where the dependent variable is categorical and has only two possible values. In logistic regression, we use the sigmoid function to calculate the probability of an event Y, given some features X as:

                                          P(Y)=1/(1 + exp(-X))
"""

# Defining the Logistic regression model
lg = LogisticRegression()

# Fitting the model on the training data
lg.fit(x_train,y_train)

"""#### Checking the performance on the train dataset"""

#Predicting for train set
y_pred_train = lg.predict(x_train)

#checking the performance on the train dataset
metrics_score(y_train, y_pred_train)

"""#### Checking the performance on the test dataset"""

#Predicting for test set
y_pred_test = lg.predict(x_test)

#checking the performance on the test dataset
metrics_score(y_test, y_pred_test)

"""**Observations:**

- **We are getting an accuracy of about 80%** on the train and the test datasets.
- However, **the recall for this model is only around 9% for class 1 on the train data and 8% on the test data.**
- As the recall is low, **this model will not perform well** in differentiating out clients who have a high chance of defaulting the loan, meaning it will eventually not help in increasing the bank income.
- As we can see from the Confusion Matrix, **this model is not good at identifying clients who are at risk of defaulting.**

#### Let's check the coefficients, and check which variables are important and how they affect the process of loan approval
"""

# Printing the coefficients of logistic regression

cols = X_scaled.columns

coef_lg = lg.coef_

pd.DataFrame(coef_lg,columns = cols).T.sort_values(by = 0, ascending = False)

"""**Insights:**

**Features which positively affect on the defaulted rate are:**
- DEBTINC
- NINQ

**Features which negatively affect on the defaulted rate are:**
- MORTDUE
- CLAGE

The coefficients of the logistic regression model give us the log of odds, which is hard to interpret in the real world. We can convert the log of odds into odds by taking its exponential.
"""

odds = np.exp(lg.coef_[0]) # Finding the odds

# Adding the odds to a DataFrame and sorting the values
pd.DataFrame(odds, x_train.columns, columns = ['odds']).sort_values(by = 'odds', ascending = False)

"""- The odds of defaulting for a client with high debt/income ratio is 50% higher than one with low ratio.
- The odds of defaulting for a client with many recent credit inquiries is ~34% higher than one with a small number.

**The Precision-Recall Curve for Logistic Regression**
"""

y_scores_lg = lg.predict_proba(x_train) # predict_proba gives the probability of each observation belonging to each class


precisions_lg, recalls_lg, thresholds_lg = precision_recall_curve(y_train, y_scores_lg[:, 1])

# Plot values of precisions, recalls, and thresholds
plt.figure(figsize = (10, 7))

plt.plot(thresholds_lg, precisions_lg[:-1], 'b--', label = 'precision')

plt.plot(thresholds_lg, recalls_lg[:-1], 'g--', label = 'recall')

plt.xlabel('Threshold')

plt.legend(loc = 'upper left')

plt.ylim([0, 1])

plt.show()

"""**Observation:**
- We can see that the precision and the recall are balanced for a threshold of about **0.28**.

**Let's find out the performance of the model at this threshold.**
"""

optimal_threshold1 = .28

y_pred_train = lg.predict_proba(x_train)

metrics_score(y_train, y_pred_train[:, 1] > optimal_threshold1)

"""**Observations:**

- **The model performance has improved. The recall has increased significantly for class 1 to 41%.**
- Let's check the performance on the test data.
"""

optimal_threshold1 = .28

y_pred_test = lg.predict_proba(x_test)

metrics_score(y_test, y_pred_test[:, 1] > optimal_threshold1)

"""**Observations:**

- The model is giving a **similar performance on the test and the train datasets**, i.e., the model is giving a generalized performance.
- **The recall of the test data has increased to 41%** while at the same time, the precision has decreased slightly, which is to be expected while adjusting the threshold.
- Nevertheless, Recall is still low.

### **Build a Decision Tree Model**

**Observation: We aren't going to treat de outliers** in order to build the model because small changes in the training data can result in a large change in the tree and consequently the final predictions.

#### Data Preparation for the tree based model
"""

df.info()

#copying df to another variable
data = df.copy()

"""#### Separating the target variable y and independent variable x"""

# Separating the target variable and other variables
Y = data.BAD
X = data.drop(columns = ['BAD'])

# Creating the list of columns for which we need to create the dummy variables
to_get_dummies_for = ['REASON', 'JOB']

# Creating dummy variables
X = pd.get_dummies(data = X, columns = to_get_dummies_for, drop_first = True)

X

"""#### Split the data"""

# Split the data into training and test set (We use Stratify = 1 because data is unbalanced)
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1, stratify = Y)

#Defining Decision tree model with class weights class_weight={0: 0.2, 1: 0.8}
dt = DecisionTreeClassifier(class_weight = {0: 0.2, 1: 0.8}, random_state = 1)

#fitting Decision tree model
dt.fit(x_train, y_train)

"""#### Checking the performance on the train dataset"""

# Checking performance on the training data

y_train_pred_dt = dt.predict(x_train)

metrics_score(y_train, y_train_pred_dt)

"""#### Checking the performance on the test dataset"""

# Checking performance on the testing data

y_test_pred_dt = dt.predict(x_test)

metrics_score(y_test, y_test_pred_dt)

"""**Insights**

- The Decision Tree works well on the training data but **not so well on the test data** as the recall is 0.62 in comparison to 1.00 for the training dataset, i.e., the Decision Tree is **overfitting the training data.**
- The precision on the test data suggests that there's a 27% (1 - 0.73) chance that the model will predict that a client is going to default even though he/she would not (false positive), increasing the risk for  **the bank to loses income.**
- The **recall** in this model is greater than in logistical regression: 0.62 vs. 0.41.

### **Decision Tree - Hyperparameter Tuning**

* We'll use Grid search to perform hyperparameter tuning.
* **Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.**
* **It is an exhaustive search** that is performed on the specific parameter values of a model.
* The parameters of the estimator/model used to apply these methods are **optimized by cross-validated grid-search** over a parameter grid.

**Let's plot the feature importance and check the most important features.**
"""

# Plotting the feature importance

importances = dt.feature_importances_

columns = X.columns

importance_df = pd.DataFrame(importances, index = columns, columns = ['Importance']).sort_values(by = 'Importance', ascending = False)

plt.figure(figsize = (13, 13))

sns.barplot(importance_df.Importance,importance_df.index)

"""- According to the Decision Tree, DEBTINC_missing_values_flag is the most important feature, followed by DEBTINC, CLAGE and LOAN.
- This might signify that any client with no data in the DEBTINC ratio, will not receive any loan.
- The other important features are MORTDUE, VALUE.

#### Using GridSearchCV for Hyperparameter tuning on the model
"""

# Choosing the type of classifier.
dtree_estimator = DecisionTreeClassifier(class_weight = {0: 0.2, 1: 0.8}, random_state = 1)

# Grid of parameters to choose from
parameters = {'max_depth': np.arange(2, 7),
              'criterion': ['gini', 'entropy'],
              'min_samples_leaf': [5, 10, 20, 25]
             }

# Type of scoring used to compare parameter combinations
scorer = metrics.make_scorer(recall_score, pos_label = 1)

# Run the grid search
gridCV = GridSearchCV(dtree_estimator, parameters, scoring = scorer, cv = 10)


# Fitting the GridSearch on train dataset
gridCV = gridCV.fit(x_train, y_train)


# Setting the clf to the best combination of parameters
dtree_estimator = gridCV.best_estimator_


# Fitting the best algorithm to the data.
dtree_estimator.fit(x_train, y_train)

"""#### Checking the performance on the train dataset"""

# Checking performance on the training data based on the tuned model

y_train_pred_dt = dtree_estimator.predict(x_train)

metrics_score(y_train, y_train_pred_dt)

"""#### Checking the performance on the test dataset"""

# Checking performance on the testing data based on the tuned model

y_test_pred_dt = dtree_estimator.predict(x_test)

metrics_score(y_test, y_test_pred_dt)

"""**Insights**

- In comparison to the model with default values of hyperparameters, **the performance on the training set has gone down significantly (1.00 to 0.74)** This makes sense because we are trying to reduce overfitting.
- The tuned model is performing well in comparison to the model with default values of hyperparameters: **Recall increases from 0.61 to 0.74** in test data.
- **This model is not overfitting** the training data and giving approximately the same result on the test and train datasets.
- **Precision has gone down significantly from .73 to .62** in comparison to the previous model which means the tuned model will give a high number of false positives, i.e., this model will predict the client is going to default even if he/she won't, and this will increases the risk of losing income.

**Let's look at the feature importance of this model and try to analyze why this is happening.**
"""

importances = dtree_estimator.feature_importances_

columns = X.columns

importance_df = pd.DataFrame(importances, index = columns, columns = ['Importance']).sort_values(by = 'Importance', ascending = False)

plt.figure(figsize = (13, 13))

sns.barplot(importance_df.Importance, importance_df.index)

"""**Observations:**

- After tuning the model we are getting that only 8 features are important. It seems like **the model is having high bias**, as it has over-simplified the problem and is not capturing the patterns associated with other variables.
- According to this model too, `DEBTINC_missing_value`, `DEBTINC`, `DELINQ`, `CLAGE`, `DEROG`, `CLNO`, `MORTDUE`and `YOG` are the most important features that describe why a client is defaulting.

#### Plotting the Decision Tree
"""

# Plotting the decision  tree and analyze it to build the decision rule

features = list(X.columns)

plt.figure(figsize = (30, 20))

tree.plot_tree(dt, max_depth = 5, feature_names = features, filled = True, fontsize = 12, node_ids = True, class_names = True)

plt.show()

"""### **Note:**

Blue leaves represent the attrition, i.e., **y[1]** and the orange leaves represent the non-attrition, i.e., **y[0]**. Also, the more the number of observations in a leaf, the darker its color gets.

**Business rules:**

- When DEBTINC ratio data isn't present and the client has delinquent credit lines and the age of the oldest credit line is smaller than 390.6 months, then the client have a hign chance to default.
- When DEBTINC ratio data isn't present and the client doesn't have delinquent credit lines, he/she has a high chance to default.
- If the DEBTINC ratio data is present and the DEBTINC ratio is greater than 43.7 and the age of the oldest credit line is smaller than 285.5 months, the client has a chance to default.
- If the DEBTINC ratio data is present and the DEBTINC ratio is smaller than 43.7 but the client has derogatory reports, he/she has a chance to default.
- If the DEBTINC ratio data is present and the DEBTINC ratio is smaller than 43.7 but VALUE isn't present, there is chance to default.
- If the DEBTINC ratio data is present and the DEBTINC ratio is smaller than 43.7 and VALUE is present, there is a high chance to not default.
- If the DEBTINC ratio data is present and the DEBTINC ratio is greater than 43.7 and the age of the oldest credit line is greater than 285.5 months, the client won't default.
- When DEBTINC ratio data isn't present and the client has delinquent credit lines and the age of the oldest credit line is greater than 390.6 months, then the client won't default.

### **Building a Random Forest Classifier**
"""

# Defining Random forest CLassifier

rf_estimator = RandomForestClassifier(random_state = 1)

rf_estimator.fit(x_train, y_train)

"""#### Checking the performance on the train dataset"""

#Checking performance on the training data

y_pred_train_rf = rf_estimator.predict(x_train)

metrics_score(y_train, y_pred_train_rf)

"""#### Checking the performance on the test dataset"""

# Checking performance on the test data

y_pred_test_rf = rf_estimator.predict(x_test)

metrics_score(y_test, y_pred_test_rf)

"""**Observations:**

- The Random Forest classifier **seems to be overfitting the training data**. The recall on the training data is 1, while the **recall** on the test data is only **0.68 for class 1 (lower than the tuned Decision Tree).**
- Precision is high for the test data as well.

### **Build a Random Forest model with Class Weights**
"""

# Defining Random Forest model with class weights class_weight={0: 0.2, 1: 0.8}
rf_estimator = RandomForestClassifier(class_weight = {0: 0.2, 1: 0.8}, random_state = 1)

# Fitting Random Forest model
rf_estimator.fit(x_train, y_train)

"""#### Checking the performance on the train dataset"""

# Checking performance on the train data

y_pred_train_rf = rf_estimator.predict(x_train)

metrics_score(y_train, y_pred_train_rf)

"""#### Checking the performance on the test dataset"""

# Checking performance on the test data

y_pred_test_rf = rf_estimator.predict(x_test)

metrics_score(y_test, y_pred_test_rf)

"""**Observations**

- The random forest classifier is still **overfitting** in the training data.
- **Recall** decreased from **.68 to .63**.
- Precision is still high for the test data as well.
- Using class_weight={0: 0.2, 1: 0.8} got worse results. When we increase class weight for class 0, recall improves a little bit, for instance: class_weight={0: 0.5, 1: 0.5} which is the default classifier we obtained a higher recall 0.68.

#### Plot the Feature importance of the Random Forest
"""

# importance of features in the tree building
importances = rf_estimator.feature_importances_

columns = X.columns

importance_df = pd.DataFrame(importances, index = columns, columns = ['Importance']).sort_values(by = 'Importance', ascending = False)

plt.figure(figsize = (13, 13))

sns.barplot(importance_df.Importance, importance_df.index)

"""### **Tuning the Random Forest**

* We'll use Grid search to perform hyperparameter tuning.
* **Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.**
* **It is an exhaustive search** that is performed on the specific parameter values of a model.
* The parameters of the estimator/model used to apply these methods are **optimized by cross-validated grid-search** over a parameter grid.

#### **Warning:** This will take a long time.
"""

# Choosing the type of classifier.
rf_estimator_tuned = RandomForestClassifier(random_state = 1)

# Grid of parameters to choose from
params_rf = {
        "n_estimators": [100, 250, 500],
        "min_samples_leaf": np.arange(1, 4, 1),
        "max_features": [0.7, 0.9, 'auto'],
}

# Type of scoring used to compare parameter combinations
scorer = metrics.make_scorer(recall_score, pos_label = 1)


# Running the grid search
grid_obj = GridSearchCV(rf_estimator_tuned, params_rf, scoring = scorer, cv = 5)


#fitting the GridSearch on train dataset
grid_obj = grid_obj.fit(x_train, y_train)


# Setting the clf to the best combination of parameters
rf_estimator_tuned = grid_obj.best_estimator_


# Fitting the best algorithm to the data.
rf_estimator_tuned.fit(x_train, y_train)

"""#### Checking the performance on the train dataset"""

# Checking performance on the training data
y_pred_train_rf_tuned = rf_estimator_tuned.predict(x_train)

metrics_score(y_train, y_pred_train_rf_tuned)

"""#### Checking the performance on the test dataset"""

# Checking performace on test dataset
y_pred_test_rf_tuned = rf_estimator_tuned.predict(x_test)

metrics_score(y_test, y_pred_test_rf_tuned)

"""**Insights:**

- The tuned model is also **overfitting the training dataset** but it shows a good performance on the test dataset.
- The **recall** for class 1 has improved to .68 in comparison to non-tuned random forest model (.63) with a small decrease in precision on the test dataset.
- The **recall in this model is still not better** than the tuned decision tree (.68 vs .74), but **precision is much better (.82 vs .62).**

#### Plotting the Feature importance of the tuned Random Forest
"""

# Checking performace on test dataset

importances = rf_estimator_tuned.feature_importances_

columns = X.columns

importance_df = pd.DataFrame(importances, index = columns, columns = ['Importance']).sort_values(by = 'Importance', ascending = False)

plt.figure(figsize = (13, 13))

sns.barplot(importance_df.Importance, importance_df.index)

"""**Observations**

- **The feature importance plot for the base model and tuned model are quite similar.** The model seems to suggest that `DEBTINC_missing_value_flag`, `DEBTINC`, `CLAGE`, and `DELINQ` are the most important features.
- Other important features are VALUE, CLNO, LOAN, and MORTDUE.

### **Comparing Model Performances**
"""

def get_recall_score(model,flag=True,X_train=x_train,X_test=x_test):
    '''
    model : classifier to predict values of X

    '''
    a = [] # defining an empty list to store train and test results
    pred_train = model.predict(X_train)
    pred_test = model.predict(X_test)
    train_recall = metrics.recall_score(y_train,pred_train)
    test_recall = metrics.recall_score(y_test,pred_test)
    a.append(train_recall) # adding train recall to list
    a.append(test_recall) # adding test recall to list

    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.
    if flag == True:
        print("Recall on training set : ",metrics.recall_score(y_train,pred_train))
        print("Recall on test set : ",metrics.recall_score(y_test,pred_test))

    return a # returning the list with train and test scores

##  Function to calculate precision score
def get_precision_score(model,flag=True,X_train=x_train,X_test=x_test):
    '''
    model : classifier to predict values of X

    '''
    b = []  # defining an empty list to store train and test results
    pred_train = model.predict(X_train)
    pred_test = model.predict(X_test)
    train_precision = metrics.precision_score(y_train,pred_train)
    test_precision = metrics.precision_score(y_test,pred_test)
    b.append(train_precision) # adding train precision to list
    b.append(test_precision) # adding test precision to list

    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.
    if flag == True:
        print("Precision on training set : ",metrics.precision_score(y_train,pred_train))
        print("Precision on test set : ",metrics.precision_score(y_test,pred_test))

    return b # returning the list with train and test scores

##  Function to calculate accuracy score
def get_accuracy_score(model,flag=True,X_train=x_train,X_test=x_test):
    '''
    model : classifier to predict values of X

    '''
    c = [] # defining an empty list to store train and test results
    train_acc = model.score(X_train,y_train)
    test_acc = model.score(X_test,y_test)
    c.append(train_acc) # adding train accuracy to list
    c.append(test_acc) # adding test accuracy to list

    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.
    if flag == True:
        print("Accuracy on training set : ",model.score(X_train,y_train))
        print("Accuracy on test set : ",model.score(X_test,y_test))

    return c # returning the list with train and test scores

# Making the list of all the model names

#models = [lg, dt, dtree_estimator, rf_estimator, rf_estimator_tuned]
models = [rf_estimator_tuned, rf_estimator, dtree_estimator, dt]

# defining empty lists to add train and test results
acc_train = []
acc_test = []
recall_train = []
recall_test = []
precision_train = []
precision_test = []

# looping through all the models to get the accuracy,recall and precision scores
for model in models:

     # precision score
    l = get_precision_score(model,False)
    precision_train.append(l[0])
    precision_test.append(l[1])

    # accuracy score
    j = get_accuracy_score(model,False)
    acc_train.append(j[0])
    acc_test.append(j[1])

    # recall score
    k = get_recall_score(model,False)
    recall_train.append(k[0])
    recall_test.append(k[1])

# Mentioning the Model names in the list.
comparison_frame = pd.DataFrame({'Model':['Tuned Random Forest', 'Random Forest', 'Tuned Decision Tree', 'Decision Tree'],
                                          'Train_Accuracy': acc_train,
                                          'Test_Accuracy': acc_test,
                                          'Train_Recall': recall_train,
                                          'Test_Recall': recall_test,
                                          'Train_Precision': precision_train,
                                          'Test_Precision': precision_test})
comparison_frame

"""**Insights:**

- Models with the **higher test accuracy are the Random Forest and Tuned Random Forest ~.90**
- All models **overfit** the training data with the exception of the Tuned Decision Tree.
- The highest **recall (~0.74) belongs to the Tuned Decision Tree**. The others are similars.
- **Precision in Random Forest models** are similar and high (+.82). Is also higher than Decision Tree models.
- **Precision in the Decision Tree** is higher than in the Tuned Decision Tree (~.73 vs ~.62).
"""